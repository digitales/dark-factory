import{_ as n,o as i,c as s,a0 as o,j as e,a as r,t as l}from"./chunks/framework.B3sz4m_N.js";const f=JSON.parse('{"title":"Prompt Engineering as a Development Discipline","description":"","frontmatter":{},"headers":[],"relativePath":"docs/prompt-engineering/README.md","filePath":"docs/prompt-engineering/README.md"}'),p={name:"docs/prompt-engineering/README.md"};function d(a,t,m,c,u,g){return i(),s("div",null,[t[9]||(t[9]=o('<h1 id="prompt-engineering-as-a-development-discipline" tabindex="-1">Prompt Engineering as a Development Discipline <a class="header-anchor" href="#prompt-engineering-as-a-development-discipline" aria-label="Permalink to &quot;Prompt Engineering as a Development Discipline&quot;">​</a></h1><p>This folder contains research and deliverables for <strong>formalising prompt engineering</strong> as a development discipline. It covers version-controlled prompt libraries, benchmarking, cost/token ROI, standard prompt formats, and governance.</p><h2 id="contents" tabindex="-1">Contents <a class="header-anchor" href="#contents" aria-label="Permalink to &quot;Contents&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Document</th><th>Description</th></tr></thead><tbody><tr><td><a href="./01-internal-policy-template.html">01-internal-policy-template.md</a></td><td><strong>Internal policy template</strong> — Version control, benchmarking, cost tracking, standard formats (code audits, plugin reviews, refactoring, documentation), governance model.</td></tr><tr><td><a href="./02-repository-structure-proposal.html">02-repository-structure-proposal.md</a></td><td><strong>Repository structure proposal</strong> — Layout for <code>prompt-library/</code> with <code>prompts/</code>, <code>evaluations/</code>, <code>benchmarks/</code>, <code>schemas/</code>, and workflows.</td></tr><tr><td><a href="./03-evaluation-rubric.html">03-evaluation-rubric.md</a></td><td><strong>Evaluation rubric</strong> — 15-criteria scoring (1–5 each, total 75), interpretation, thresholds, and use-case-specific emphasis.</td></tr></tbody></table><h2 id="research-basis" tabindex="-1">Research basis <a class="header-anchor" href="#research-basis" aria-label="Permalink to &quot;Research basis&quot;">​</a></h2>',5)),e("ul",null,[t[5]||(t[5]=e("li",null,[e("strong",null,"Version-controlled prompts:"),r(" PromptG, Langfuse, ell, PromptOps — prompts as code with git, labels, rollback.")],-1)),t[6]||(t[6]=e("li",null,[e("strong",null,"Benchmarking:"),r(" PromptBench, PromptEval, LiveBench — multi-prompt evaluation, robustness across templates.")],-1)),t[7]||(t[7]=e("li",null,[e("strong",null,"Cost/token ROI:"),r(" Langfuse, LangSmith, Datadog LLM Observability — automatic token/cost tracking, budgets, ROI correlation.")],-1)),e("li",null,[t[0]||(t[0]=e("strong",null,"Standard format:",-1)),t[1]||(t[1]=r(" MoritzLaurer/prompt_templates — YAML/JSON with ",-1)),t[2]||(t[2]=e("code",null,"prompt.template",-1)),t[3]||(t[3]=r(", ",-1)),e("code",null,l(a.variables),1),t[4]||(t[4]=r(", metadata, client_parameters.",-1))]),t[8]||(t[8]=e("li",null,[e("strong",null,"Governance:"),r(" PromptOpsGuide.org (Reliability, Governance, Evaluation, Lifecycle, Human–AI Interfaces); Prompt Commons; policy-as-prompt considerations.")],-1))]),t[10]||(t[10]=o('<h2 id="quick-links" tabindex="-1">Quick links <a class="header-anchor" href="#quick-links" aria-label="Permalink to &quot;Quick links&quot;">​</a></h2><ul><li><a href="https://www.promptopsguide.org/" target="_blank" rel="noreferrer">PromptOps Guide</a></li><li><a href="https://moritzlaurer.com/prompt_templates/standard_prompt_format/" target="_blank" rel="noreferrer">Standard Prompt Format</a></li><li><a href="https://langfuse.com/docs/prompt-management" target="_blank" rel="noreferrer">Langfuse Prompt Management</a></li></ul>',2))])}const b=n(p,[["render",d]]);export{f as __pageData,b as default};
