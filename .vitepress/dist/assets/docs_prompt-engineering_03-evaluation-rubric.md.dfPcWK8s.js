import{_ as o,o as s,c as l,a0 as r,j as t,a as i,t as n}from"./chunks/framework.B3sz4m_N.js";const k=JSON.parse('{"title":"Prompt Evaluation Rubric","description":"","frontmatter":{},"headers":[],"relativePath":"docs/prompt-engineering/03-evaluation-rubric.md","filePath":"docs/prompt-engineering/03-evaluation-rubric.md"}'),d={name:"docs/prompt-engineering/03-evaluation-rubric.md"};function p(a,e,c,h,u,m){return s(),l("div",null,[e[5]||(e[5]=r('<h1 id="prompt-evaluation-rubric" tabindex="-1">Prompt Evaluation Rubric <a class="header-anchor" href="#prompt-evaluation-rubric" aria-label="Permalink to &quot;Prompt Evaluation Rubric&quot;">​</a></h1><p><strong>Document type:</strong> Evaluation rubric<br><strong>Version:</strong> 1.0<br><strong>Status:</strong> Draft for adoption<br><strong>Use:</strong> Assess prompts before promotion to production; gate PRs; periodic audits.</p><hr><h2 id="_1-purpose" tabindex="-1">1. Purpose <a class="header-anchor" href="#_1-purpose" aria-label="Permalink to &quot;1. Purpose&quot;">​</a></h2><p>This rubric provides a <strong>standardised way to score and improve prompts</strong> used in the prompt library. Use it to:</p><ul><li>Review new or changed prompts before production</li><li>Run automated or human evaluations in CI or periodic audits</li><li>Compare prompt versions and prioritise refinements</li></ul><p>Scores and thresholds can be set in policy (e.g. “minimum total score 50/75 for production”).</p><hr><h2 id="_2-scoring-model" tabindex="-1">2. Scoring model <a class="header-anchor" href="#_2-scoring-model" aria-label="Permalink to &quot;2. Scoring model&quot;">​</a></h2><ul><li><strong>15 criteria</strong>, each scored <strong>1 (Poor) to 5 (Excellent)</strong>.</li><li><strong>Total score: out of 75.</strong></li><li>For each criterion: record <strong>strength</strong>, <strong>improvement</strong>, and <strong>rationale</strong> (for feedback and audits).</li></ul><hr><h2 id="_3-the-15-criteria" tabindex="-1">3. The 15 criteria <a class="header-anchor" href="#_3-the-15-criteria" aria-label="Permalink to &quot;3. The 15 criteria&quot;">​</a></h2><h3 id="_1-clarity-specificity" tabindex="-1">1. Clarity &amp; specificity <a class="header-anchor" href="#_1-clarity-specificity" aria-label="Permalink to &quot;1. Clarity &amp; specificity&quot;">​</a></h3><ul><li><strong>1:</strong> Vague, ambiguous, or overloaded with unrelated instructions.</li><li><strong>5:</strong> Clear, specific, and focused; no unnecessary wording.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_2-context-background-provided" tabindex="-1">2. Context / background provided <a class="header-anchor" href="#_2-context-background-provided" aria-label="Permalink to &quot;2. Context / background provided&quot;">​</a></h3><ul><li><strong>1:</strong> No context; model must guess domain, constraints, or audience.</li><li><strong>5:</strong> Sufficient context (domain, constraints, audience) so the model can respond appropriately.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_3-explicit-task-definition" tabindex="-1">3. Explicit task definition <a class="header-anchor" href="#_3-explicit-task-definition" aria-label="Permalink to &quot;3. Explicit task definition&quot;">​</a></h3><ul><li><strong>1:</strong> Task is implied or unclear.</li><li><strong>5:</strong> Task is explicitly stated (e.g. “Audit this code for security issues and list findings”).</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_4-desired-output-format-style" tabindex="-1">4. Desired output format / style <a class="header-anchor" href="#_4-desired-output-format-style" aria-label="Permalink to &quot;4. Desired output format / style&quot;">​</a></h3><ul><li><strong>1:</strong> No guidance on format or style; output may be inconsistent.</li><li><strong>5:</strong> Output format and style are specified (e.g. “Structured list: severity, location, recommendation”; “Markdown with headers”).</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_5-instruction-placement-structure" tabindex="-1">5. Instruction placement &amp; structure <a class="header-anchor" href="#_5-instruction-placement-structure" aria-label="Permalink to &quot;5. Instruction placement &amp; structure&quot;">​</a></h3><ul><li><strong>1:</strong> Critical instructions buried or scattered; hard to parse.</li><li><strong>5:</strong> Important instructions are placed where they are seen first; logical order (e.g. role → task → format → input).</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_6-use-of-role-or-persona" tabindex="-1">6. Use of role or persona <a class="header-anchor" href="#_6-use-of-role-or-persona" aria-label="Permalink to &quot;6. Use of role or persona&quot;">​</a></h3><ul><li><strong>1:</strong> No role; generic “assistant” behaviour.</li><li><strong>5:</strong> Clear role/persona (e.g. “senior security-focused developer”) that steers tone and depth.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_7-examples-or-demonstrations" tabindex="-1">7. Examples or demonstrations <a class="header-anchor" href="#_7-examples-or-demonstrations" aria-label="Permalink to &quot;7. Examples or demonstrations&quot;">​</a></h3><ul><li><strong>1:</strong> No examples; model infers from description only.</li><li><strong>5:</strong> One or more concrete examples (input/output or format) that illustrate the desired behaviour.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_8-step-by-step-reasoning-encouraged" tabindex="-1">8. Step-by-step reasoning encouraged <a class="header-anchor" href="#_8-step-by-step-reasoning-encouraged" aria-label="Permalink to &quot;8. Step-by-step reasoning encouraged&quot;">​</a></h3><ul><li><strong>1:</strong> No guidance on reasoning; short or opaque answers.</li><li><strong>5:</strong> Explicitly asks for step-by-step reasoning where useful (e.g. “Explain your reasoning for each finding”).</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_9-avoiding-ambiguity-contradictions" tabindex="-1">9. Avoiding ambiguity &amp; contradictions <a class="header-anchor" href="#_9-avoiding-ambiguity-contradictions" aria-label="Permalink to &quot;9. Avoiding ambiguity &amp; contradictions&quot;">​</a></h3><ul><li><strong>1:</strong> Contradictory or ambiguous instructions; model may pick one interpretation arbitrarily.</li><li><strong>5:</strong> Consistent instructions; ambiguities resolved or explicitly scoped.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_10-iteration-refinement-potential" tabindex="-1">10. Iteration / refinement potential <a class="header-anchor" href="#_10-iteration-refinement-potential" aria-label="Permalink to &quot;10. Iteration / refinement potential&quot;">​</a></h3>',49)),t("ul",null,[e[4]||(e[4]=t("li",null,[t("strong",null,"1:"),i(" Single-shot only; hard to refine without full rewrite.")],-1)),t("li",null,[e[0]||(e[0]=t("strong",null,"5:",-1)),e[1]||(e[1]=i(" Variables and structure allow reuse and iteration (e.g. ",-1)),t("code",null,n(a.focus),1),e[2]||(e[2]=i(", ",-1)),t("code",null,n(a.language),1),e[3]||(e[3]=i(") and minor edits.",-1))])]),e[6]||(e[6]=r(`<p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_11-model-fit-scenario-appropriateness" tabindex="-1">11. Model fit / scenario appropriateness <a class="header-anchor" href="#_11-model-fit-scenario-appropriateness" aria-label="Permalink to &quot;11. Model fit / scenario appropriateness&quot;">​</a></h3><ul><li><strong>1:</strong> Asks for capabilities the model lacks (e.g. real-time data, heavy computation) or mismatched to typical use.</li><li><strong>5:</strong> Task and constraints are appropriate for the target model and scenario (e.g. code audit, doc generation).</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_12-brevity-vs-detail-balance" tabindex="-1">12. Brevity vs. detail balance <a class="header-anchor" href="#_12-brevity-vs-detail-balance" aria-label="Permalink to &quot;12. Brevity vs. detail balance&quot;">​</a></h3><ul><li><strong>1:</strong> Either overly long (noise) or too terse (missing critical detail).</li><li><strong>5:</strong> Right level of detail for the task; no redundant or missing instructions.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_13-audience-specification" tabindex="-1">13. Audience specification <a class="header-anchor" href="#_13-audience-specification" aria-label="Permalink to &quot;13. Audience specification&quot;">​</a></h3><ul><li><strong>1:</strong> Audience unknown; output may be too technical or too simple.</li><li><strong>5:</strong> Audience is specified (e.g. “for developers familiar with WordPress”) so tone and depth are appropriate.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_14-structured-numbered-instructions" tabindex="-1">14. Structured / numbered instructions <a class="header-anchor" href="#_14-structured-numbered-instructions" aria-label="Permalink to &quot;14. Structured / numbered instructions&quot;">​</a></h3><ul><li><strong>1:</strong> Wall of text; hard to follow and to update.</li><li><strong>5:</strong> Numbered or bulleted sections; easy to scan and modify.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h3 id="_15-feasibility-within-model-constraints" tabindex="-1">15. Feasibility within model constraints <a class="header-anchor" href="#_15-feasibility-within-model-constraints" aria-label="Permalink to &quot;15. Feasibility within model constraints&quot;">​</a></h3><ul><li><strong>1:</strong> Asks for output that exceeds context length, or for strict formats the model often breaks.</li><li><strong>5:</strong> Output length and format are feasible; fallbacks or constraints are stated if needed.</li></ul><p><em>Strength / Improvement / Rationale:</em></p><hr><h2 id="_4-output-format-for-evaluations" tabindex="-1">4. Output format for evaluations <a class="header-anchor" href="#_4-output-format-for-evaluations" aria-label="Permalink to &quot;4. Output format for evaluations&quot;">​</a></h2><p>When running an evaluation (human or tool-assisted), record results in this structure:</p><div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">1.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Clarity &amp; Specificity – X/5</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">   -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Strength: [</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline;">Insert</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">   -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Improvement: [</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline;">Insert</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">   -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Rationale: [</span><span style="--shiki-light:#032F62;--shiki-light-text-decoration:underline;--shiki-dark:#DBEDFF;--shiki-dark-text-decoration:underline;">Insert</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">2.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Context / Background Provided – X/5</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">   ...</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(repeat for all 15 criteria)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Total Score: X/75</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Refinement summary:</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [Suggestion 1]</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [Suggestion 2]</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [Suggestion 3]</span></span></code></pre></div><hr><h2 id="_5-interpretation-and-thresholds" tabindex="-1">5. Interpretation and thresholds <a class="header-anchor" href="#_5-interpretation-and-thresholds" aria-label="Permalink to &quot;5. Interpretation and thresholds&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Total score</th><th>Interpretation</th><th>Suggested action</th></tr></thead><tbody><tr><td>7–25</td><td>Poor</td><td>Do not promote to production; rewrite with rubric in mind.</td></tr><tr><td>26–45</td><td>Fair</td><td>Significant edits required; re-evaluate after changes.</td></tr><tr><td>46–60</td><td>Good</td><td>Minor improvements; acceptable for production with review.</td></tr><tr><td>61–75</td><td>Excellent</td><td>Production-ready; use as reference for other prompts.</td></tr></tbody></table><p><strong>Policy recommendation:</strong> Set a minimum total score (e.g. 50/75) and/or minimum per-criterion (e.g. no criterion below 3) for production promotion. Document in Internal Policy.</p><hr><h2 id="_6-use-case-specific-emphasis" tabindex="-1">6. Use-case-specific emphasis <a class="header-anchor" href="#_6-use-case-specific-emphasis" aria-label="Permalink to &quot;6. Use-case-specific emphasis&quot;">​</a></h2><p>For <strong>code audits</strong> and <strong>plugin reviews</strong>, weight these criteria higher when scoring:</p><ul><li>Explicit task definition (3)</li><li>Desired output format / style (4)</li><li>Use of role or persona (6)</li><li>Avoiding ambiguity &amp; contradictions (9)</li><li>Feasibility within model constraints (15)</li></ul><p>For <strong>refactoring</strong> and <strong>documentation</strong>, also emphasise:</p><ul><li>Context / background provided (2)</li><li>Examples or demonstrations (7)</li><li>Audience specification (13)</li></ul><hr><h2 id="_7-references" tabindex="-1">7. References <a class="header-anchor" href="#_7-references" aria-label="Permalink to &quot;7. References&quot;">​</a></h2><ul><li>15-criteria model adapted from prompt evaluation practice (e.g. Docsbot Prompt Evaluation Rubric).</li><li>Policy: <a href="./01-internal-policy-template.html">Internal Policy Template</a>.</li><li>Repo: <a href="./02-repository-structure-proposal.html">Repository Structure Proposal</a> (<code>evaluations/</code>, <code>benchmarks/</code>).</li></ul>`,38))])}const f=o(d,[["render",p]]);export{k as __pageData,f as default};
