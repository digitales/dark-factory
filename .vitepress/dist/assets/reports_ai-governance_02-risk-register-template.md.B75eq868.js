import{_ as e,o as r,c as i,a0 as a}from"./chunks/framework.B3sz4m_N.js";const h=JSON.parse('{"title":"AI Risk Register Template — Enterprise WordPress & Laravel Client Projects","description":"","frontmatter":{},"headers":[],"relativePath":"reports/ai-governance/02-risk-register-template.md","filePath":"reports/ai-governance/02-risk-register-template.md"}'),s={name:"reports/ai-governance/02-risk-register-template.md"};function n(o,t,d,l,c,g){return r(),i("div",null,[...t[0]||(t[0]=[a('<h1 id="ai-risk-register-template-—-enterprise-wordpress-laravel-client-projects" tabindex="-1">AI Risk Register Template — Enterprise WordPress &amp; Laravel Client Projects <a class="header-anchor" href="#ai-risk-register-template-—-enterprise-wordpress-laravel-client-projects" aria-label="Permalink to &quot;AI Risk Register Template — Enterprise WordPress &amp; Laravel Client Projects&quot;">​</a></h1><p><strong>Purpose:</strong> Central tracking for identifying, assessing, and managing AI-related risks in client delivery.<br><strong>Audience:</strong> Risk managers, governance teams, compliance officers, delivery leads.<br><strong>Usage:</strong> 30–45 min initial setup; ongoing updates as tools and engagements change.</p><hr><h2 id="how-to-use-this-template" tabindex="-1">How to Use This Template <a class="header-anchor" href="#how-to-use-this-template" aria-label="Permalink to &quot;How to Use This Template&quot;">​</a></h2><ol><li><strong>Update regularly</strong> as AI tools, regulations, and client engagements evolve.</li><li><strong>Implement controls</strong> starting with the example measures, then add organisation-specific policies.</li><li><strong>Assign risk owners</strong> to named individuals or teams for monitoring and escalation.</li><li><strong>Assess likelihood and residual risk</strong> using your existing risk rating framework (e.g. 1–5 or low/medium/high).</li><li><strong>Tailor</strong> risks to your industry, client mix, and regulatory context (e.g. GDPR, sector rules).</li><li><strong>Connect</strong> this register to your main GRC processes and enterprise risk register.</li></ol><hr><h2 id="risk-rating-guidance" tabindex="-1">Risk Rating Guidance <a class="header-anchor" href="#risk-rating-guidance" aria-label="Permalink to &quot;Risk Rating Guidance&quot;">​</a></h2><ul><li><strong>Likelihood:</strong> Probability the risk will materialise (e.g. 1 = rare, 5 = almost certain).</li><li><strong>Impact:</strong> Severity if it does (e.g. 1 = negligible, 5 = critical — financial, legal, reputational).</li><li><strong>Residual risk:</strong> After controls (re-assess periodically).</li><li><strong>Risk owner:</strong> Person accountable for monitoring and response.</li></ul><hr><h2 id="ai-risk-register" tabindex="-1">AI Risk Register <a class="header-anchor" href="#ai-risk-register" aria-label="Permalink to &quot;AI Risk Register&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Risk ID</th><th>Risk Name</th><th>Description</th><th>Potential Impact</th><th>Example Control Measures</th><th>Likelihood</th><th>Residual Risk</th><th>Risk Owner</th></tr></thead><tbody><tr><td>R1</td><td>Regulatory non-compliance</td><td>Use of AI that breaches GDPR, CCPA, Privacy Act, consumer law, or sector rules (e.g. financial, health).</td><td>Fines, sanctions, loss of client trust, contract termination, forced shutdown.</td><td>Legal/DPIA review; align with DPA and client contracts; maintain audit trail of AI decisions and approvals.</td><td></td><td></td><td></td></tr><tr><td>R2</td><td>Data leakage to third-party AI</td><td>Client or proprietary data (code, PII, configs) sent to SaaS AI and retained or used for training.</td><td>Breach of contract/DPA, regulatory action, reputational damage, IP loss.</td><td>Approved tools only; PII redaction pipeline; contractual no-training clauses; zero/minimal persistence; canary/fingerprinting.</td><td></td><td></td><td></td></tr><tr><td>R3</td><td>PII exposure without lawful basis</td><td>Client personal data processed by AI without valid legal basis or client approval.</td><td>GDPR/CCPA fines, complaints, enforcement, client exit.</td><td>Data minimisation; redaction before external AI; Tier 3 client approval; document legal basis per use case.</td><td></td><td></td><td></td></tr><tr><td>R4</td><td>Bias and discrimination</td><td>AI-assisted decisions (e.g. content, recommendations, support) embed or amplify bias.</td><td>Discrimination claims, reputational harm, client complaints.</td><td>Human review for sensitive decisions; fairness testing where applicable; diverse review; clear accountability.</td><td></td><td></td><td></td></tr><tr><td>R5</td><td>Misinformation and hallucination</td><td>AI generates incorrect code, content, or advice presented as factual.</td><td>Defects, security issues, wrong client deliverables, reputational loss.</td><td>Human review of critical outputs; verification steps; clear labelling of AI-generated content; testing and QA.</td><td></td><td></td><td></td></tr><tr><td>R6</td><td>Vendor lock-in and dependency</td><td>Heavy reliance on a single AI provider without exit strategy or portability.</td><td>Cost increase, loss of flexibility, exposure if provider changes terms or discontinues.</td><td>Multi-vendor strategy; contract clauses for data portability; retain in-house capability; contingency plans.</td><td></td><td></td><td></td></tr><tr><td>R7</td><td>Operational failure</td><td>Over-automation or inadequate oversight causes delivery or security failures.</td><td>Service disruption, client dissatisfaction, security incidents.</td><td>Defined human oversight points; fallback procedures; testing before rollout; change and release controls.</td><td></td><td></td><td></td></tr><tr><td>R8</td><td>Insecure AI-generated code</td><td>AI suggests vulnerable code (e.g. SQLi, XSS, auth bypass) that is merged without review.</td><td>Security breaches, client data compromise, liability.</td><td>AI-assisted SAST/SCA in CI; human review for security-sensitive changes; approved secure-coding tools only.</td><td></td><td></td><td></td></tr><tr><td>R9</td><td>Shadow AI and policy bypass</td><td>Teams use unapproved AI tools to avoid slow or heavy approval processes.</td><td>Uncontrolled data exposure, compliance gaps, no audit trail.</td><td>Fast, risk-tiered approval; allowlist for low-risk tools; training; monitoring and exception handling.</td><td></td><td></td><td></td></tr><tr><td>R10</td><td>Reputational backlash</td><td>Public or client perception that AI use is unsafe, unethical, or non-compliant.</td><td>Brand damage, client attrition, tender disadvantage.</td><td>Transparent AI policy; client communication; alignment with responsible AI norms; independent review where appropriate.</td><td></td><td></td><td></td></tr></tbody></table><p><em>Add rows for client- or project-specific risks (e.g. sector regulations, contractual clauses).</em></p><hr><h2 id="assessment-lenses" tabindex="-1">Assessment Lenses <a class="header-anchor" href="#assessment-lenses" aria-label="Permalink to &quot;Assessment Lenses&quot;">​</a></h2><p>When assessing each risk, consider:</p><table tabindex="0"><thead><tr><th>Lens</th><th>Questions</th></tr></thead><tbody><tr><td><strong>Reputation &amp; trust</strong></td><td>How might clients, regulators, or the media react if this risk materialises?</td></tr><tr><td><strong>Governance &amp; oversight</strong></td><td>Who approves, monitors, and reviews AI use? Are escalation paths clear?</td></tr><tr><td><strong>Technology reliability</strong></td><td>What are the limits of the AI (accuracy, hallucinations)? In what contexts do errors matter?</td></tr><tr><td><strong>Human impact</strong></td><td>How are staff, end users, or data subjects affected by errors, bias, or automation?</td></tr><tr><td><strong>Data sensitivity</strong></td><td>What data is processed (PII, confidential, IP)? What harm could exposure cause?</td></tr><tr><td><strong>Legal &amp; regulatory</strong></td><td>Which laws and standards apply (GDPR, CCPA, sector rules, contracts)?</td></tr><tr><td><strong>Business context</strong></td><td>Where is AI used (client-facing, internal, which stack — WordPress/Laravel)? How critical to delivery?</td></tr></tbody></table><hr><h2 id="integration-with-grc" tabindex="-1">Integration with GRC <a class="header-anchor" href="#integration-with-grc" aria-label="Permalink to &quot;Integration with GRC&quot;">​</a></h2><ul><li><strong>Link to enterprise risk register:</strong> Map AI risks to existing risk categories and owners.</li><li><strong>Review cadence:</strong> At least quarterly for high-risk items; annually for full register.</li><li><strong>Reporting:</strong> Include AI risk summary in governance/board reporting where relevant.</li><li><strong>Trigger updates:</strong> New tool adoption, new client type, incident, or regulatory change.</li></ul><hr><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">​</a></h2><ul><li>[ ] Populate likelihood, residual risk, and risk owner for your context.</li><li>[ ] Add client- or engagement-specific rows.</li><li>[ ] Align with <a href="./reports/ai-governance/01-governance-framework-draft.html">Governance Framework</a> and <a href="./reports/ai-governance/03-tooling-stack.html">Tooling Stack</a>.</li><li>[ ] Schedule first review date and assign owner for register maintenance.</li></ul><p><em>Template inspired by SafeAI-Aus AI Risk Register (CC BY 4.0). Adapt to your jurisdiction and seek legal/compliance input.</em></p>',23)])])}const u=e(s,[["render",n]]);export{h as __pageData,u as default};
