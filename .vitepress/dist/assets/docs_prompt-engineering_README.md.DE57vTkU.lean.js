import{_ as n,o as i,c as s,a0 as o,j as e,a as r,t as l}from"./chunks/framework.B3sz4m_N.js";const f=JSON.parse('{"title":"Prompt Engineering as a Development Discipline","description":"","frontmatter":{},"headers":[],"relativePath":"docs/prompt-engineering/README.md","filePath":"docs/prompt-engineering/README.md"}'),p={name:"docs/prompt-engineering/README.md"};function d(a,t,m,c,u,g){return i(),s("div",null,[t[9]||(t[9]=o("",5)),e("ul",null,[t[5]||(t[5]=e("li",null,[e("strong",null,"Version-controlled prompts:"),r(" PromptG, Langfuse, ell, PromptOps — prompts as code with git, labels, rollback.")],-1)),t[6]||(t[6]=e("li",null,[e("strong",null,"Benchmarking:"),r(" PromptBench, PromptEval, LiveBench — multi-prompt evaluation, robustness across templates.")],-1)),t[7]||(t[7]=e("li",null,[e("strong",null,"Cost/token ROI:"),r(" Langfuse, LangSmith, Datadog LLM Observability — automatic token/cost tracking, budgets, ROI correlation.")],-1)),e("li",null,[t[0]||(t[0]=e("strong",null,"Standard format:",-1)),t[1]||(t[1]=r(" MoritzLaurer/prompt_templates — YAML/JSON with ",-1)),t[2]||(t[2]=e("code",null,"prompt.template",-1)),t[3]||(t[3]=r(", ",-1)),e("code",null,l(a.variables),1),t[4]||(t[4]=r(", metadata, client_parameters.",-1))]),t[8]||(t[8]=e("li",null,[e("strong",null,"Governance:"),r(" PromptOpsGuide.org (Reliability, Governance, Evaluation, Lifecycle, Human–AI Interfaces); Prompt Commons; policy-as-prompt considerations.")],-1))]),t[10]||(t[10]=o("",2))])}const b=n(p,[["render",d]]);export{f as __pageData,b as default};
