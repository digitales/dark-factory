import{_ as s,o as n,c as e,a0 as t}from"./chunks/framework.B3sz4m_N.js";const u=JSON.parse('{"title":"Repository Structure Proposal: Prompt Library and Evaluation","description":"","frontmatter":{},"headers":[],"relativePath":"docs/prompt-engineering/02-repository-structure-proposal.md","filePath":"docs/prompt-engineering/02-repository-structure-proposal.md"}'),i={name:"docs/prompt-engineering/02-repository-structure-proposal.md"};function p(r,a,o,l,d,c){return n(),e("div",null,[...a[0]||(a[0]=[t(`<h1 id="repository-structure-proposal-prompt-library-and-evaluation" tabindex="-1">Repository Structure Proposal: Prompt Library and Evaluation <a class="header-anchor" href="#repository-structure-proposal-prompt-library-and-evaluation" aria-label="Permalink to &quot;Repository Structure Proposal: Prompt Library and Evaluation&quot;">​</a></h1><p><strong>Document type:</strong> Proposal<br><strong>Version:</strong> 1.0<br><strong>Status:</strong> Draft for adoption</p><hr><h2 id="_1-overview" tabindex="-1">1. Overview <a class="header-anchor" href="#_1-overview" aria-label="Permalink to &quot;1. Overview&quot;">​</a></h2><p>This proposal defines a <strong>version-controlled prompt library</strong> and supporting structure so that prompts are treated as first-class, reviewable assets. The layout supports:</p><ul><li>Version control (git) for every prompt and evaluation</li><li>Standard prompt formats (YAML/JSON) with variables and metadata</li><li>Benchmarking and evaluation suites with recorded results</li><li>Cost and token tracking metadata/artefacts</li><li>Governance (ownership, labels, approval workflow)</li></ul><hr><h2 id="_2-root-layout" tabindex="-1">2. Root layout <a class="header-anchor" href="#_2-root-layout" aria-label="Permalink to &quot;2. Root layout&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>prompt-library/                    # Dedicated repo or monorepo subtree</span></span>
<span class="line"><span>├── README.md                      # Purpose, how to add/run prompts, link to policy</span></span>
<span class="line"><span>├── .github/</span></span>
<span class="line"><span>│   └── workflows/</span></span>
<span class="line"><span>│       ├── validate-prompts.yml   # Lint/validate YAML structure, required vars</span></span>
<span class="line"><span>│       ├── run-evaluations.yml    # Run evaluation suite on changed prompts</span></span>
<span class="line"><span>│       └── cost-report.yml        # Optional: aggregate token/cost from observability</span></span>
<span class="line"><span>├── prompts/                       # Versioned prompt templates</span></span>
<span class="line"><span>│   ├── code-audit/</span></span>
<span class="line"><span>│   ├── plugin-review/</span></span>
<span class="line"><span>│   ├── refactoring/</span></span>
<span class="line"><span>│   └── documentation/</span></span>
<span class="line"><span>├── evaluations/                   # Evaluation configs and expected behaviour</span></span>
<span class="line"><span>├── benchmarks/                    # Benchmark datasets and run results</span></span>
<span class="line"><span>├── schemas/                       # JSON Schema (or equivalent) for prompt format</span></span>
<span class="line"><span>└── docs/                          # In-repo docs (or link to policy/report)</span></span>
<span class="line"><span>    └── GOVERNANCE.md</span></span></code></pre></div><hr><h2 id="_3-prompts-—-prompt-templates-by-use-case" tabindex="-1">3. <code>prompts/</code> — Prompt templates by use case <a class="header-anchor" href="#_3-prompts-—-prompt-templates-by-use-case" aria-label="Permalink to &quot;3. \`prompts/\` — Prompt templates by use case&quot;">​</a></h2><p>Each subdirectory corresponds to a <strong>standard use case</strong> (see Internal Policy). One prompt = one file (or a small set of variants). Naming: <code>kebab-case.yaml</code> or <code>.json</code>.</p><h3 id="_3-1-structure-per-file" tabindex="-1">3.1 Structure per file <a class="header-anchor" href="#_3-1-structure-per-file" aria-label="Permalink to &quot;3.1 Structure per file&quot;">​</a></h3><ul><li>Follow the <a href="https://moritzlaurer.com/prompt_templates/standard_prompt_format/" target="_blank" rel="noreferrer">Standard Prompt Format</a>: <code>prompt.template</code>, <code>prompt.template_variables</code>, <code>prompt.metadata</code>, <code>prompt.client_parameters</code>.</li><li><code>metadata</code> MUST include: <code>name</code>, <code>version</code> (semver), <code>tags</code> (e.g. <code>code-audit</code>, <code>security</code>).</li><li>Optional: <code>metadata.owner</code>, <code>metadata.labels</code> (e.g. <code>production</code>, <code>staging</code>).</li></ul><h3 id="_3-2-suggested-layout" tabindex="-1">3.2 Suggested layout <a class="header-anchor" href="#_3-2-suggested-layout" aria-label="Permalink to &quot;3.2 Suggested layout&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>prompts/</span></span>
<span class="line"><span>├── code-audit/</span></span>
<span class="line"><span>│   ├── security-audit.yaml</span></span>
<span class="line"><span>│   ├── style-audit.yaml</span></span>
<span class="line"><span>│   └── accessibility-audit.yaml</span></span>
<span class="line"><span>├── plugin-review/</span></span>
<span class="line"><span>│   ├── wp-plugin-review.yaml</span></span>
<span class="line"><span>│   └── plugin-security-checklist.yaml</span></span>
<span class="line"><span>├── refactoring/</span></span>
<span class="line"><span>│   ├── extract-function.yaml</span></span>
<span class="line"><span>│   ├── rename-and-clean.yaml</span></span>
<span class="line"><span>│   └── modernise-php.yaml</span></span>
<span class="line"><span>└── documentation/</span></span>
<span class="line"><span>    ├── api-docs-from-code.yaml</span></span>
<span class="line"><span>    ├── readme-from-spec.yaml</span></span>
<span class="line"><span>    └── inline-comments.yaml</span></span></code></pre></div><h3 id="_3-3-example-prompts-code-audit-security-audit-yaml" tabindex="-1">3.3 Example: <code>prompts/code-audit/security-audit.yaml</code> <a class="header-anchor" href="#_3-3-example-prompts-code-audit-security-audit-yaml" aria-label="Permalink to &quot;3.3 Example: \`prompts/code-audit/security-audit.yaml\`&quot;">​</a></h3><div class="language-yaml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">  template</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    - </span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">role</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;system&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">      content</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        You are a senior developer performing a security-focused code audit.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        Output a structured list of findings: severity, location, issue, recommendation.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    - </span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">role</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">      content</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        Language: {{language}}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        Focus: {{focus}}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        Context: {{context}}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        Code:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        \`\`\`{{language}}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        {{code}}</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        \`\`\`</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">  template_variables</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">language</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">focus</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">context</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">code</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">  metadata</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">    name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Security Code Audit&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">    version</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;0.1.0&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">    tags</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">code-audit</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">security</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">    owner</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;platform-team&quot;</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">  client_parameters</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">    temperature</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span></span></code></pre></div><hr><h2 id="_4-evaluations-—-evaluation-configs-and-criteria" tabindex="-1">4. <code>evaluations/</code> — Evaluation configs and criteria <a class="header-anchor" href="#_4-evaluations-—-evaluation-configs-and-criteria" aria-label="Permalink to &quot;4. \`evaluations/\` — Evaluation configs and criteria&quot;">​</a></h2><ul><li><strong>Purpose:</strong> Define test inputs and pass/fail (or scoring) criteria for prompts.</li><li><strong>Per-prompt:</strong> One evaluation config per prompt (or per variant). Naming: <code>{prompt-name}.yaml</code> or under <code>{use-case}/{prompt-name}.yaml</code>.</li></ul><p>Suggested structure:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>evaluations/</span></span>
<span class="line"><span>├── code-audit/</span></span>
<span class="line"><span>│   ├── security-audit.yaml       # Inputs + expected output criteria</span></span>
<span class="line"><span>│   └── style-audit.yaml</span></span>
<span class="line"><span>├── plugin-review/</span></span>
<span class="line"><span>│   └── wp-plugin-review.yaml</span></span>
<span class="line"><span>├── refactoring/</span></span>
<span class="line"><span>│   └── modernise-php.yaml</span></span>
<span class="line"><span>└── _shared/</span></span>
<span class="line"><span>    └── rubric-criteria.yaml      # Reference to evaluation rubric (e.g. 15-point)</span></span></code></pre></div><p>Evaluation file contents (conceptual):</p><ul><li><strong>inputs:</strong> List of <code>{variable: value}</code> cases (e.g. sample code, focus area).</li><li><strong>expected:</strong> Criteria (e.g. “must mention X”, “must not suggest Y”, “output must be valid JSON”).</li><li><strong>metrics:</strong> Optional: latency budget, max tokens, cost ceiling.</li></ul><p>Tools that fit: custom scripts, <a href="https://www.promptfoo.dev/" target="_blank" rel="noreferrer">promptfoo</a>, or CI that calls your LLM and checks outputs against criteria.</p><hr><h2 id="_5-benchmarks-—-benchmark-data-and-results" tabindex="-1">5. <code>benchmarks/</code> — Benchmark data and results <a class="header-anchor" href="#_5-benchmarks-—-benchmark-data-and-results" aria-label="Permalink to &quot;5. \`benchmarks/\` — Benchmark data and results&quot;">​</a></h2><ul><li><strong>Purpose:</strong> Store benchmark datasets and historical run results for regression and comparison.</li><li><strong>Datasets:</strong> E.g. <code>benchmarks/datasets/code-audit/samples.jsonl</code> (one JSON object per line: inputs + optional reference output).</li><li><strong>Results:</strong> E.g. <code>benchmarks/results/code-audit/security-audit/YYYY-MM-DD.json</code> (run timestamp, model, token counts, scores, pass/fail).</li></ul><p>Suggested structure:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>benchmarks/</span></span>
<span class="line"><span>├── datasets/</span></span>
<span class="line"><span>│   ├── code-audit/</span></span>
<span class="line"><span>│   ├── plugin-review/</span></span>
<span class="line"><span>│   └── documentation/</span></span>
<span class="line"><span>├── results/</span></span>
<span class="line"><span>│   ├── code-audit/</span></span>
<span class="line"><span>│   │   └── security-audit/</span></span>
<span class="line"><span>│   └── ...</span></span>
<span class="line"><span>└── README.md                     # How to run benchmarks, interpret results</span></span></code></pre></div><hr><h2 id="_6-schemas-—-validation" tabindex="-1">6. <code>schemas/</code> — Validation <a class="header-anchor" href="#_6-schemas-—-validation" aria-label="Permalink to &quot;6. \`schemas/\` — Validation&quot;">​</a></h2><ul><li><strong>prompt-schema.json:</strong> JSON Schema for the standard prompt format (top-level <code>prompt</code>, <code>template</code>, <code>template_variables</code>, <code>metadata</code>, <code>client_parameters</code>).</li><li>CI can validate every file under <code>prompts/</code> against this schema.</li></ul><hr><h2 id="_7-governance-and-workflows" tabindex="-1">7. Governance and workflows <a class="header-anchor" href="#_7-governance-and-workflows" aria-label="Permalink to &quot;7. Governance and workflows&quot;">​</a></h2><ul><li><strong>GOVERNANCE.md:</strong> Short summary of roles (owner, reviewer, governance lead), lifecycle (design → evaluate → review → deploy → monitor), and how labels (e.g. <code>production</code>) are assigned. Link to Internal Policy.</li><li><strong>Branching:</strong> Prompts changed on a branch; PR triggers validation and (where possible) evaluation run; merge to main = eligible for production after approval.</li><li><strong>Labels/environments:</strong> Can be tracked in metadata or in an external system (e.g. Langfuse labels); document in README how “production” is set (e.g. “prompts on main with label production in Langfuse”).</li></ul><hr><h2 id="_8-cost-and-token-roi" tabindex="-1">8. Cost and token ROI <a class="header-anchor" href="#_8-cost-and-token-roi" aria-label="Permalink to &quot;8. Cost and token ROI&quot;">​</a></h2><ul><li><strong>In-repo:</strong> <code>benchmarks/results/</code> can store token counts and cost per run (if exported from your observability stack).</li><li><strong>External:</strong> Prefer an observability platform (Langfuse, LangSmith, Datadog, etc.) for live cost tracking; link from README and policy.</li><li><strong>ROI:</strong> Document in README or docs how to pull cost per prompt/task and compare to value (e.g. time saved, error rate) for governance reviews.</li></ul><hr><h2 id="_9-summary" tabindex="-1">9. Summary <a class="header-anchor" href="#_9-summary" aria-label="Permalink to &quot;9. Summary&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Area</th><th>Location</th><th>Purpose</th></tr></thead><tbody><tr><td>Versioned prompts</td><td><code>prompts/{use-case}/*.yaml</code></td><td>Single source of truth, standard format</td></tr><tr><td>Evaluation criteria</td><td><code>evaluations/{use-case}/*.yaml</code></td><td>Test inputs and pass/fail or scoring</td></tr><tr><td>Benchmark data &amp; results</td><td><code>benchmarks/datasets/</code>, <code>benchmarks/results/</code></td><td>Regression, comparison, token/cost history</td></tr><tr><td>Validation</td><td><code>schemas/prompt-schema.json</code> + CI</td><td>Enforce structure and required fields</td></tr><tr><td>Governance</td><td><code>docs/GOVERNANCE.md</code>, PR + approval</td><td>Lifecycle, roles, production promotion</td></tr></tbody></table><p>This structure keeps prompts as code, evaluable and auditable, and aligns with the Internal Policy and Evaluation Rubric.</p>`,44)])])}const m=s(i,[["render",p]]);export{u as __pageData,m as default};
