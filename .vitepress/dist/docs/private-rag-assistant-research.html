<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Private RAG Assistant for WordPress + Laravel Dev Team | Elixirr Digital</title>
    <meta name="description" content="Research report — spec-driven development, consultancy dynamics, and adoption for PHP, WordPress and Laravel teams.">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="./assets/style.CU4gt7pX.css" as="style">
    <link rel="preload stylesheet" href="./vp-icons.css" as="style">
    
    <script type="module" src="./assets/app.D1zh8-61.js"></script>
    <link rel="preload" href="./assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="./assets/chunks/framework.B3sz4m_N.js">
    <link rel="modulepreload" href="./assets/chunks/theme.C4O1iYSY.js">
    <link rel="modulepreload" href="./assets/chunks/katex.CBSAILhF.js">
    <link rel="modulepreload" href="./assets/chunks/dagre-6UL2VRFP.LfGySJdO.js">
    <link rel="modulepreload" href="./assets/chunks/cose-bilkent-S5V4N54A.Die6I3eL.js">
    <link rel="modulepreload" href="./assets/chunks/c4Diagram-YG6GDRKO.YN7iDvAN.js">
    <link rel="modulepreload" href="./assets/chunks/flowDiagram-NV44I4VS.B4W7gki_.js">
    <link rel="modulepreload" href="./assets/chunks/erDiagram-Q2GNP2WA.B4tRgiMB.js">
    <link rel="modulepreload" href="./assets/chunks/gitGraphDiagram-V2S2FVAM.CJ4bdSt4.js">
    <link rel="modulepreload" href="./assets/chunks/ganttDiagram-JELNMOA3.EbaiLyol.js">
    <link rel="modulepreload" href="./assets/chunks/infoDiagram-HS3SLOUP.BCjwNfW9.js">
    <link rel="modulepreload" href="./assets/chunks/pieDiagram-ADFJNKIX.Czilmfwt.js">
    <link rel="modulepreload" href="./assets/chunks/quadrantDiagram-AYHSOK5B.10zwTEL-.js">
    <link rel="modulepreload" href="./assets/chunks/xychartDiagram-PRI3JC2R.i0XWlC4v.js">
    <link rel="modulepreload" href="./assets/chunks/requirementDiagram-UZGBJVZJ.BY1btfDm.js">
    <link rel="modulepreload" href="./assets/chunks/sequenceDiagram-WL72ISMW.CNLLIh-p.js">
    <link rel="modulepreload" href="./assets/chunks/classDiagram-2ON5EDUG.Snj2-Dhr.js">
    <link rel="modulepreload" href="./assets/chunks/classDiagram-v2-WZHVMYZB.Snj2-Dhr.js">
    <link rel="modulepreload" href="./assets/chunks/stateDiagram-FKZM4ZOC.CKzNew20.js">
    <link rel="modulepreload" href="./assets/chunks/stateDiagram-v2-4FDKWEC3.DezNEUFs.js">
    <link rel="modulepreload" href="./assets/chunks/journeyDiagram-XKPGCS4Q.CsX-u0ls.js">
    <link rel="modulepreload" href="./assets/chunks/timeline-definition-IT6M3QCI.Djo-ukwv.js">
    <link rel="modulepreload" href="./assets/chunks/mindmap-definition-VGOIOE7T.BbuGhTor.js">
    <link rel="modulepreload" href="./assets/chunks/kanban-definition-3W4ZIXB7.BXhJBpQo.js">
    <link rel="modulepreload" href="./assets/chunks/sankeyDiagram-TZEHDZUN.BvKq3_8R.js">
    <link rel="modulepreload" href="./assets/chunks/diagram-S2PKOQOG.CFlb4uAr.js">
    <link rel="modulepreload" href="./assets/chunks/diagram-QEK2KX5R.BRLv94zI.js">
    <link rel="modulepreload" href="./assets/chunks/blockDiagram-VD42YOAC.CJTizxQm.js">
    <link rel="modulepreload" href="./assets/chunks/architectureDiagram-VXUJARFQ.DHlhApQm.js">
    <link rel="modulepreload" href="./assets/chunks/diagram-PSM6KHXK.CVt9EKsv.js">
    <link rel="modulepreload" href="./assets/chunks/virtual_mermaid-config.DDnGl6nM.js">
    <link rel="modulepreload" href="./assets/docs_private-rag-assistant-research.md.pyAV33r6.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-f71b9d1b><!----><div class="layout-content" data-v-f71b9d1b><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-f71b9d1b data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/" data-v-9f43907a><!--[--><!--]--><!----><span data-v-9f43907a>Research</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="./" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="./reports/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Reports</span><!--]--></a><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://www.elixirrdigital.com" target="_blank" rel="noreferrer" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>Elixirr Digital</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://www.linkedin.com/company/elixirr-digital" aria-label="linkedin" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-linkedin"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><!----><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://www.linkedin.com/company/elixirr-digital" aria-label="linkedin" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-linkedin"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-f71b9d1b data-v-2488c25a><div class="container" data-v-2488c25a><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-f71b9d1b data-v-9a6c75ad><div class="VPDoc has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _docs_private-rag-assistant-research" data-v-e6f2a212><div><h1 id="private-rag-assistant-for-wordpress-laravel-dev-team" tabindex="-1">Private RAG Assistant for WordPress + Laravel Dev Team <a class="header-anchor" href="#private-rag-assistant-for-wordpress-laravel-dev-team" aria-label="Permalink to &quot;Private RAG Assistant for WordPress + Laravel Dev Team&quot;">​</a></h1><p><strong>Research document</strong> — Deployment runbooks, Jira exports, infrastructure docs, plugin documentation, internal Markdown.</p><hr><h2 id="_1-embedding-model-selection" tabindex="-1">1. Embedding model selection <a class="header-anchor" href="#_1-embedding-model-selection" aria-label="Permalink to &quot;1. Embedding model selection&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Criterion</th><th>Recommendation</th><th>Notes</th></tr></thead><tbody><tr><td><strong>Best balance (POC)</strong></td><td><strong>e5-base-v2</strong> or <strong>BAAI/bge-base-en-v1.5</strong></td><td>~100M params, 100% Top-5 accuracy in benchmarks, low latency (~16–50 ms).</td></tr><tr><td><strong>Highest retrieval quality</strong></td><td><strong>e5-large-instruct</strong> or <strong>BGE-large</strong></td><td>85%+ retrieval accuracy; stronger for mixed code + prose.</td></tr><tr><td><strong>Lightweight / CPU-only</strong></td><td><strong>e5-small</strong> (118M)</td><td>Fastest (16 ms), good Top-5 accuracy; suitable for small teams or dev machines.</td></tr><tr><td><strong>Self-hosted, popular</strong></td><td><strong>nomic-embed-text</strong> (768 dims)</td><td>Well-supported, good for docs + code; fits Ollama/local stacks.</td></tr></tbody></table><p><strong>Avoid for production:</strong> <code>all-MiniLM-L6-v2</code> (outdated, ~56% Top-5 accuracy).</p><p><strong>Self-hosting:</strong> Use <strong>Ollama</strong> for local inference or <strong>Sentence Transformers</strong> in Python; keep embeddings on your infra to satisfy data residency.</p><p><strong>For WordPress/Laravel:</strong> Prefer <strong>multilingual-capable</strong> models (e.g. BGE, e5) if runbooks or Jira use mixed languages; otherwise English-focused models (e5-*, BGE-en) are sufficient.</p><hr><h2 id="_2-vector-database-comparison" tabindex="-1">2. Vector database comparison <a class="header-anchor" href="#_2-vector-database-comparison" aria-label="Permalink to &quot;2. Vector database comparison&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Database</th><th>Self-hosted</th><th>Latency (P95)</th><th>Indexing (1M vectors)</th><th>Typical cost (self-hosted)</th><th>Best for</th></tr></thead><tbody><tr><td><strong>Qdrant</strong></td><td>✅</td><td>22–38 ms</td><td>~6 min</td><td>~$120/mo (r6g.xlarge)</td><td>Performance, filtering, Rust/APACHE 2.0</td></tr><tr><td><strong>Weaviate</strong></td><td>✅</td><td>38–65 ms</td><td>~9 min</td><td>~$120/mo (r6g.xlarge)</td><td>Hybrid (vector + keyword), GraphQL, multi-tenant</td></tr><tr><td><strong>Chroma</strong></td><td>✅</td><td>180–340 ms</td><td>~28 min</td><td>~$60/mo (t3.large)</td><td>Prototyping, local dev, tight budget</td></tr><tr><td><strong>Pinecone</strong></td><td>❌ managed only</td><td>—</td><td>—</td><td>~$3k/mo (performance tier)</td><td>Skip for “private” requirement</td></tr></tbody></table><p><strong>Recommendation for POC:</strong> <strong>Qdrant</strong> (Docker, low ops) or <strong>Chroma</strong> (fastest to stand up). For production with hybrid search (Jira + code + Markdown), <strong>Weaviate</strong> is a strong option.</p><p><strong>Recall:</strong> All in the 0.94–0.98 range for typical RAG; choice matters more for scale, filtering, and ops.</p><hr><h2 id="_3-chunking-strategies-code-vs-docs" tabindex="-1">3. Chunking strategies: code vs docs <a class="header-anchor" href="#_3-chunking-strategies-code-vs-docs" aria-label="Permalink to &quot;3. Chunking strategies: code vs docs&quot;">​</a></h2><h3 id="documentation-runbooks-infra-docs-markdown-jira-exports" tabindex="-1">Documentation (runbooks, infra docs, Markdown, Jira exports) <a class="header-anchor" href="#documentation-runbooks-infra-docs-markdown-jira-exports" aria-label="Permalink to &quot;Documentation (runbooks, infra docs, Markdown, Jira exports)&quot;">​</a></h3><ul><li><strong>Preferred:</strong> <strong>Semantic chunking</strong> — split at meaning boundaries (sections, paragraphs) rather than fixed token counts. <ul><li><strong>Embedding-based:</strong> Compute similarity between adjacent sentences; split when similarity drops (e.g. cosine &lt; threshold). ~85–91% retrieval accuracy vs ~75–80% for fixed-size.</li><li><strong>NLP-based:</strong> Use spaCy (or similar) for section/topic boundaries.</li></ul></li><li><strong>Overlap:</strong> 50–100 tokens overlap at chunk boundaries to avoid cutting context.</li><li><strong>Sizes:</strong> Variable; aim for ~200–800 tokens per chunk so full procedures stay together.</li></ul><h3 id="source-code-plugins-laravel-app-code" tabindex="-1">Source code (plugins, Laravel app code) <a class="header-anchor" href="#source-code-plugins-laravel-app-code" aria-label="Permalink to &quot;Source code (plugins, Laravel app code)&quot;">​</a></h3><ul><li><strong>Preferred:</strong> <strong>AST-based chunking</strong> (e.g. <strong>cAST</strong>, <strong>Tree-sitter</strong>). <ul><li>Preserve <strong>function/class/module</strong> boundaries; avoid splitting mid-function.</li><li>Tree-sitter supports 29+ languages (PHP, JavaScript, etc.) and fits WordPress/Laravel stacks.</li><li><strong>Results:</strong> ~4.3 pt gain Recall@5 vs fixed-size; ~2.67 pt Pass@1 on code-generation tasks.</li></ul></li><li><strong>Fallback:</strong> Recursive character/text splitting with <strong>code-aware separators</strong> (e.g. <code>\n\n</code>, <code>function </code>, <code>class </code>) and max chunk size (~512 tokens).</li></ul><h3 id="mixed-content-plugin-docs-code-snippets" tabindex="-1">Mixed content (plugin docs + code snippets) <a class="header-anchor" href="#mixed-content-plugin-docs-code-snippets" aria-label="Permalink to &quot;Mixed content (plugin docs + code snippets)&quot;">​</a></h3><ul><li>Use <strong>two pipelines:</strong> one semantic for prose, one AST for code; tag chunks with <code>type: doc | code</code> and <strong>language</strong> for filtering.</li><li>Store <strong>metadata:</strong> <code>source</code> (e.g. repo, Confluence, Jira), <code>doc_type</code> (runbook, API, README), <code>project</code> (WordPress plugin X, Laravel app Y).</li></ul><hr><h2 id="_4-security-and-access-control" tabindex="-1">4. Security and access control <a class="header-anchor" href="#_4-security-and-access-control" aria-label="Permalink to &quot;4. Security and access control&quot;">​</a></h2><ul><li><strong>Authentication:</strong> Central IdP (e.g. <strong>SSO/SAML/OIDC</strong>). No shared API keys for end-users.</li><li><strong>Authorization:</strong> Apply <strong>RBAC</strong> (or ABAC/ReBAC if needed) so retrieval only sees documents the user is allowed to see. <ul><li><strong>Pattern:</strong> Store <strong>role/project/team</strong> (or resource IDs) as metadata on chunks; at query time, filter by <code>user.roles</code> / <code>user.projects</code> before or after vector search.</li><li><strong>Post-query filtering:</strong> Run permission checks on retrieved doc IDs against your auth system to avoid leaking snippets from unauthorized runbooks or repos.</li></ul></li><li><strong>Sensitive data:</strong> Redact PII/credentials in runbooks and Jira exports <strong>before</strong> embedding (e.g. Comprehend-style or regex + allowlists). Prefer “redact at ingest” so sensitive text never enters the vector DB.</li><li><strong>Network:</strong> Run RAG stack (embeddings, vector DB, LLM) in a private VPC; expose only the RAG API (and optional web UI) through an auth gateway.</li><li><strong>Audit:</strong> Log queries and which documents were retrieved (doc IDs, not full content) for compliance and debugging.</li></ul><hr><h2 id="_5-integration-options" tabindex="-1">5. Integration options <a class="header-anchor" href="#_5-integration-options" aria-label="Permalink to &quot;5. Integration options&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Integration</th><th>Use case</th><th>Effort</th><th>Notes</th></tr></thead><tbody><tr><td><strong>Web UI</strong></td><td>Primary interface for runbooks, Jira, infra docs</td><td>Medium</td><td>Simple chat UI + source citations; auth via existing SSO. Best for POC.</td></tr><tr><td><strong>Slack</strong></td><td>“How do we…?” in channels or DMs</td><td>Medium</td><td>Bot with RAG backend; use Slack OAuth + scopes; optional RAGTime-style patterns (mention-based, threads).</td></tr><tr><td><strong>VSCode / Cursor</strong></td><td>Code-aware Q&amp;A in editor</td><td>Higher</td><td>Extensions like <strong>RAGnarōk</strong> (local embeddings + LanceDB) or custom extension calling your RAG API; good for “how does plugin X work?” with code context.</td></tr><tr><td><strong>API-only</strong></td><td>Other tools (e.g. internal dashboards, CLI)</td><td>Low</td><td>REST/GraphQL endpoint: <code>query</code> + <code>user_id</code>/<code>roles</code>; return answer + doc refs.</td></tr></tbody></table><p><strong>POC priority:</strong> Web UI first (proves value, easy to demo), then Slack; VSCode once retrieval quality is validated.</p><hr><h2 id="_6-estimated-infrastructure-costs" tabindex="-1">6. Estimated infrastructure costs <a class="header-anchor" href="#_6-estimated-infrastructure-costs" aria-label="Permalink to &quot;6. Estimated infrastructure costs&quot;">​</a></h2><p>Rough <strong>monthly</strong> ranges for a <strong>private</strong> stack (single region, no managed Pinecone/OpenAI for core RAG).</p><table tabindex="0"><thead><tr><th>Component</th><th>Low (POC / small team)</th><th>Medium (10–20 devs)</th><th>High (50+ devs, 10M+ chunks)</th></tr></thead><tbody><tr><td><strong>Embeddings</strong></td><td>Self-hosted (e5-base) on 1× CPU or small GPU: ~$50–100</td><td>1× L4 or T4 GPU: ~$200–400</td><td>Dedicated embedding tier: ~$500–1,500</td></tr><tr><td><strong>Vector DB</strong></td><td>Chroma/Qdrant single node: ~$60–120</td><td>Qdrant/Weaviate cluster: ~$300–600</td><td>~$600–1,000</td></tr><tr><td><strong>LLM inference</strong></td><td>Ollama on existing server or 1× small GPU: ~$0–150</td><td>1× A10/L4: ~$300–600</td><td>Multiple GPUs or managed: ~$1,000–3,000</td></tr><tr><td><strong>Reranker (optional)</strong></td><td>Omit or CPU: ~$0</td><td>1× small GPU: ~$100–200</td><td>~$200–500</td></tr><tr><td><strong>App + API</strong></td><td>1× small VM: ~$20–50</td><td>2–3 VMs + LB: ~$100–200</td><td>~$200–400</td></tr><tr><td><strong>Total</strong></td><td><strong>~$130–420/mo</strong></td><td><strong>~$1,000–2,000/mo</strong></td><td><strong>~$2,500–6,400/mo</strong></td></tr></tbody></table><ul><li><strong>Ingestion:</strong> One-time or batched; cost is dominated by embedding compute. 1M docs with self-hosted e5: order of hours on a single GPU, not ongoing API spend.</li><li><strong>Managed alternatives:</strong> If you later use OpenAI for embeddings (~$0.02/1M tokens), 1M docs ≈ tens of dollars one-time; 100M docs can reach ~$2k. LLM APIs (GPT-4, etc.) can push total to <strong>$50–100/day</strong> at high query volume if unoptimized.</li></ul><hr><h2 id="_7-architecture-overview" tabindex="-1">7. Architecture overview <a class="header-anchor" href="#_7-architecture-overview" aria-label="Permalink to &quot;7. Architecture overview&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>┌─────────────────────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│                           DATA SOURCES                                       │</span></span>
<span class="line"><span>│  Runbooks │ Jira (CSV/JSON/export) │ Infra docs │ Plugin docs │ Internal MD  │</span></span>
<span class="line"><span>└───────────────────────────────────┬─────────────────────────────────────────┘</span></span>
<span class="line"><span>                                    │</span></span>
<span class="line"><span>                                    ▼</span></span>
<span class="line"><span>┌─────────────────────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│  INGEST PIPELINE                                                             │</span></span>
<span class="line"><span>│  • Parsers (Markdown, HTML, Jira schema, code repos)                         │</span></span>
<span class="line"><span>│  • Chunking: semantic (docs) + AST (code, Tree-sitter)                       │</span></span>
<span class="line"><span>│  • Metadata: source, type, project, access_roles                             │</span></span>
<span class="line"><span>│  • Redaction (PII/creds) → Embedding model (e5/BGE) → Vector DB (Qdrant/…)   │</span></span>
<span class="line"><span>└───────────────────────────────────┬─────────────────────────────────────────┘</span></span>
<span class="line"><span>                                    │</span></span>
<span class="line"><span>                                    ▼</span></span>
<span class="line"><span>┌─────────────────────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│  VECTOR DB                    │  AUTH / RBAC                                │</span></span>
<span class="line"><span>│  Collections by type/project  │  User ↔ roles, projects                      │</span></span>
<span class="line"><span>└───────────────────────────────────┬─────────────────────────────────────────┘</span></span>
<span class="line"><span>                                    │</span></span>
<span class="line"><span>                                    ▼</span></span>
<span class="line"><span>┌─────────────────────────────────────────────────────────────────────────────┐</span></span>
<span class="line"><span>│  RAG SERVICE (API)                                                            │</span></span>
<span class="line"><span>│  Query → embed → vector search + metadata filter (RBAC) → rerank → LLM       │</span></span>
<span class="line"><span>│  Response + cited doc IDs/snippets                                            │</span></span>
<span class="line"><span>└───────────────────────────────────┬─────────────────────────────────────────┘</span></span>
<span class="line"><span>                                    │</span></span>
<span class="line"><span>        ┌───────────────────────────┼───────────────────────────┐</span></span>
<span class="line"><span>        ▼                           ▼                           ▼</span></span>
<span class="line"><span>┌───────────────┐         ┌─────────────────┐         ┌─────────────────┐</span></span>
<span class="line"><span>│   Web UI      │         │  Slack bot       │         │  VSCode / API   │</span></span>
<span class="line"><span>│   (primary)   │         │  (optional)     │         │  (optional)     │</span></span>
<span class="line"><span>└───────────────┘         └─────────────────┘         └─────────────────┘</span></span></code></pre></div><ul><li><strong>Private:</strong> Embedding model, vector DB, and LLM run in your VPC (or on-prem). No third-party RAG SaaS in the critical path.</li><li><strong>Access:</strong> Every query is bound to an authenticated user; vector search or post-retrieval filter enforces RBAC so only allowed runbooks/docs/code are used in the answer.</li></ul><hr><h2 id="_8-60-day-poc-plan" tabindex="-1">8. 60-day POC plan <a class="header-anchor" href="#_8-60-day-poc-plan" aria-label="Permalink to &quot;8. 60-day POC plan&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Phase</th><th>Week</th><th>Activities</th><th>Deliverables</th></tr></thead><tbody><tr><td><strong>Setup</strong></td><td>1–2</td><td>Pick stack: Ollama or Python + e5/BGE; Qdrant or Chroma in Docker. Ingest 2–3 runbooks + one plugin’s README/code.</td><td>Running pipeline; vector DB with ~500–2k chunks.</td></tr><tr><td><strong>Chunking</strong></td><td>2–3</td><td>Implement semantic chunking for Markdown/runbooks; AST (Tree-sitter) for one repo (e.g. PHP plugin). Tag <code>type</code>, <code>source</code>, <code>project</code>.</td><td>Two ingest paths; metadata in vector DB.</td></tr><tr><td><strong>RAG API</strong></td><td>3–4</td><td>Query API: embed query → search → filter by test user/role → call local LLM (Ollama) → return answer + citations.</td><td>REST or GraphQL endpoint; curl-able.</td></tr><tr><td><strong>Auth</strong></td><td>4–5</td><td>Wire SSO (or mock roles); apply role/project filter in retrieval; audit log (query + doc IDs).</td><td>Only allowed docs appear in answers.</td></tr><tr><td><strong>Web UI</strong></td><td>5–6</td><td>Simple chat UI (e.g. Streamlit, React, or Vite + your API); show sources per message.</td><td>Demo-able “internal assistant”.</td></tr><tr><td><strong>Content</strong></td><td>6–7</td><td>Ingest Jira export (e.g. epic/issue summaries + links); infra doc set; 2–3 internal Markdown hubs.</td><td>Broader coverage; ~10k–50k chunks.</td></tr><tr><td><strong>Eval</strong></td><td>7–8</td><td>Define 30–50 test questions; measure retrieval (Recall@5, MRR) and answer quality (faithfulness, relevance). Tune chunk size/overlap and model if needed.</td><td>Eval report; decision to scale or iterate.</td></tr></tbody></table><p><strong>Success criteria for POC:</strong> (1) Answers grounded in your runbooks/docs with citations. (2) No retrieval from docs the test user is not allowed to see. (3) Latency &lt; 5 s for typical query on single-node setup.</p><hr><h2 id="_9-evaluation-metrics" tabindex="-1">9. Evaluation metrics <a class="header-anchor" href="#_9-evaluation-metrics" aria-label="Permalink to &quot;9. Evaluation metrics&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Category</th><th>Metrics</th><th>How to measure</th></tr></thead><tbody><tr><td><strong>Retrieval</strong></td><td><strong>Recall@5</strong>, <strong>MRR</strong></td><td>For each test question, check if the gold doc(s) appear in top 5; compute recall and mean reciprocal rank.</td></tr><tr><td><strong>Faithfulness</strong></td><td>% of claims supported by retrieved chunks</td><td>LLM-as-judge or NLI model: “Does this passage support this claim?” — avoid hallucinations.</td></tr><tr><td><strong>Relevance</strong></td><td>Semantic match query ↔ answer</td><td>LLM-as-judge or embedding similarity (query vs answer).</td></tr><tr><td><strong>Citation</strong></td><td>Correctness of cited doc IDs</td><td>Whether cited chunks actually support the sentence they’re attached to.</td></tr><tr><td><strong>Safety / RBAC</strong></td><td>Leak rate</td><td>For each role, run queries that <em>should</em> not see certain docs; confirm those docs never appear in top-k or in citations.</td></tr></tbody></table><p><strong>Tools:</strong> <strong>Ragas</strong> (reference-free), <strong>DeepEval</strong> (RAG metrics out of the box), or custom scripts with your test Q set. Track these weekly during POC and set targets (e.g. Recall@5 &gt; 0.85, zero RBAC leaks).</p><hr><h2 id="_10-summary-and-next-steps" tabindex="-1">10. Summary and next steps <a class="header-anchor" href="#_10-summary-and-next-steps" aria-label="Permalink to &quot;10. Summary and next steps&quot;">​</a></h2><ul><li><strong>Embeddings:</strong> e5-base or BGE-base for POC; self-host via Ollama or Sentence Transformers.</li><li><strong>Vector DB:</strong> Qdrant (Docker) for performance and simplicity; Chroma for quickest POC.</li><li><strong>Chunking:</strong> Semantic for runbooks/docs/Jira/Markdown; AST (Tree-sitter) for WordPress/Laravel code.</li><li><strong>Security:</strong> SSO + RBAC on retrieval; redact sensitive data at ingest; private VPC and audit logging.</li><li><strong>Integrations:</strong> Web UI first, then Slack; VSCode/API once stable.</li><li><strong>Cost:</strong> POC ~$130–420/mo; production small team ~$1k–2k/mo depending on LLM and scale.</li></ul><p><strong>Next steps:</strong> (1) Choose one runbook and one codebase as Day-1 sources. (2) Stand up vector DB + embedding model in Docker. (3) Implement ingest with semantic + AST chunking and RBAC metadata. (4) Build minimal RAG API and web UI and run a 30-question eval by end of Week 8.</p></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter" data-v-f71b9d1b data-v-566314d4><div class="container" data-v-566314d4><p class="message" data-v-566314d4>Part of Elixirr Digital — Your digital partner.</p><p class="copyright" data-v-566314d4>Experience digital solutions that challenge the ordinary.</p></div></footer><!--[--><!--]--></div></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"docs_ai-automated-test-coverage-research.md\":\"CgcUSSgM\",\"docs_ai-wordpress-editorial-workflows-research.md\":\"CpHwjBkB\",\"docs_private-rag-assistant-research.md\":\"pyAV33r6\",\"docs_prompt-engineering_01-internal-policy-template.md\":\"DmftKxam\",\"docs_prompt-engineering_02-repository-structure-proposal.md\":\"Bs-EfFge\",\"docs_prompt-engineering_03-evaluation-rubric.md\":\"dfPcWK8s\",\"docs_prompt-engineering_readme.md\":\"DE57vTkU\",\"docs_research-ai-mysql-performance-optimisation.md\":\"ChQa3grT\",\"docs_research-semi-autonomous-devops-agents.md\":\"Cl5EauNv\",\"handover.md\":\"9N1J80m7\",\"index.md\":\"Be0LdmWR\",\"readme.md\":\"DpFfN3za\",\"reports_ai-governance_01-governance-framework-draft.md\":\"BGlKloTM\",\"reports_ai-governance_02-risk-register-template.md\":\"B75eq868\",\"reports_ai-governance_03-tooling-stack.md\":\"CPIvXu4E\",\"reports_ai-governance_index.md\":\"BDM9Lwou\",\"reports_ai-transformation-programme_01-whitepaper.md\":\"C8aUVyj9\",\"reports_ai-transformation-programme_index.md\":\"BChkFnOx\",\"reports_ai-wp-laravel-pipeline_01-research-document.md\":\"JlwN61gk\",\"reports_ai-wp-laravel-pipeline_index.md\":\"DAFai_YX\",\"reports_dark-factory_01-executive-summary.md\":\"KN5zeCYO\",\"reports_dark-factory_02-what-is-a-dark-factory.md\":\"oQ6lMezB\",\"reports_dark-factory_03-new-development-workflow.md\":\"DOIhoe5h\",\"reports_dark-factory_04-php-wordpress-laravel.md\":\"BioLer33\",\"reports_dark-factory_05-consultancy-environment.md\":\"CFgUvoOH\",\"reports_dark-factory_06-scenario-based-development.md\":\"C7gRvZOv\",\"reports_dark-factory_07-creating-specifications.md\":\"DgLx6ExX\",\"reports_dark-factory_08-spec-structure-examples.md\":\"DD-vvR3u\",\"reports_dark-factory_09-exercises-and-practice.md\":\"BM3JuSQP\",\"reports_dark-factory_10-adopting-the-shift.md\":\"CoQai92S\",\"reports_dark-factory_11-assumptions-follow-up.md\":\"DOd9BQ7Q\",\"reports_dark-factory_12-references.md\":\"BQif4lpl\",\"reports_dark-factory_ai-observability-incident-response-research.md\":\"Co2YoSGJ\",\"reports_dark-factory_index.md\":\"BGcvez_b\",\"reports_index.md\":\"QQHI2aVC\",\"research_initiatives_2026-02-23-ai-transformation-programme.md\":\"CYeXmjgd\",\"research_orchestration_00_readme.md\":\"CSo2iXAR\",\"research_orchestration_01_intake_template.md\":\"74x01o1X\",\"research_orchestration_02_run_workflow.md\":\"B3LhK_e_\",\"research_orchestration_03_synthesis_prompt.md\":\"DzQWh5si\",\"research_orchestration_04_scorecard.md\":\"QBK28vb2\",\"research_orchestration_05_decision_log_template.md\":\"UvVGtU1-\",\"research_orchestration_06_one_shot_runner_prompt.md\":\"DCHZyizQ\",\"research_orchestration_07_single_prompt_automation.md\":\"B471qctC\",\"research_orchestration_08_orchestration_checklist.md\":\"1ePfsJQb\",\"research_orchestration_workflows_initiative_workflow.md\":\"CEp2ROyi\",\"research_orchestration_workflows_portfolio_workflow.md\":\"BYwXtHNX\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Dark Factories & AI-Generated Code\",\"titleTemplate\":\":title | Elixirr Digital\",\"description\":\"Research report — spec-driven development, consultancy dynamics, and adoption for PHP, WordPress and Laravel teams.\",\"base\":\"./\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"Research\",\"logoLink\":\"/\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Reports\",\"link\":\"/reports/\"},{\"text\":\"Elixirr Digital\",\"link\":\"https://www.elixirrdigital.com\",\"target\":\"_blank\"}],\"sidebar\":{\"/reports/\":[{\"text\":\"Reports\",\"link\":\"/reports/\"},{\"text\":\"Dark Factories & AI-Generated Code\",\"link\":\"/reports/dark-factory/\"},{\"text\":\"AI in the WordPress + Laravel Pipeline\",\"link\":\"/reports/ai-wp-laravel-pipeline/\"},{\"text\":\"AI Transformation Research Programme\",\"link\":\"/reports/ai-transformation-programme/\"}],\"/reports/dark-factory/\":[{\"text\":\"Report overview\",\"link\":\"/reports/dark-factory/\"},{\"text\":\"Sections\",\"items\":[{\"text\":\"1. Executive Summary\",\"link\":\"/reports/dark-factory/01-executive-summary\"},{\"text\":\"2. What Is a Dark Factory?\",\"link\":\"/reports/dark-factory/02-what-is-a-dark-factory\"},{\"text\":\"3. New Development Workflow\",\"link\":\"/reports/dark-factory/03-new-development-workflow\"},{\"text\":\"4. PHP / WordPress & Laravel\",\"link\":\"/reports/dark-factory/04-php-wordpress-laravel\"},{\"text\":\"5. Consultancy Environment\",\"link\":\"/reports/dark-factory/05-consultancy-environment\"},{\"text\":\"6. Scenario-Based Development\",\"link\":\"/reports/dark-factory/06-scenario-based-development\"},{\"text\":\"7. Creating Specifications\",\"link\":\"/reports/dark-factory/07-creating-specifications\"},{\"text\":\"8. Spec Structure & Examples\",\"link\":\"/reports/dark-factory/08-spec-structure-examples\"},{\"text\":\"9. Exercises and Practice\",\"link\":\"/reports/dark-factory/09-exercises-and-practice\"},{\"text\":\"10. Adopting the Shift\",\"link\":\"/reports/dark-factory/10-adopting-the-shift\"},{\"text\":\"11. Assumptions & Follow-Up\",\"link\":\"/reports/dark-factory/11-assumptions-follow-up\"},{\"text\":\"12. References\",\"link\":\"/reports/dark-factory/12-references\"}]}],\"/reports/ai-transformation-programme/\":[{\"text\":\"Report overview\",\"link\":\"/reports/ai-transformation-programme/\"},{\"text\":\"1. AI Transformation Whitepaper\",\"link\":\"/reports/ai-transformation-programme/01-whitepaper\"}]},\"socialLinks\":[{\"icon\":\"linkedin\",\"link\":\"https://www.linkedin.com/company/elixirr-digital\"}],\"footer\":{\"message\":\"Part of Elixirr Digital — Your digital partner.\",\"copyright\":\"Experience digital solutions that challenge the ordinary.\"},\"outline\":{\"level\":[2,3],\"label\":\"On this page\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>